# # backend/bridge.py
#è¿‡åº¦æ–‡ä»¶ä½¿ç”¨ï¼Œå·²åºŸå¼ƒ


# import threading
# import time
# import asyncio
# import base64
# from io import BytesIO
# from PIL import Image

# from ai_assistant.core.webcam_handler import WebcamHandler
# from ai_assistant.core.emotion_engine import EmotionEngine
# from socket_manager import manager

# # === [æ–°å¢] å…¨å±€å˜é‡ï¼Œç”¨äºå­˜æ”¾ä¸»çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯ ===
# global_main_loop = None

# class HeadlessApp:
#     def __init__(self):
#         print("åˆå§‹åŒ–æ— å¤´é€‚é…å™¨...")
#         self.status_text = "åˆå§‹åŒ–ä¸­..."
#         self.emotion_engine = EmotionEngine() 
#         self.webcam_handler = WebcamHandler(self) 
#         self.after(1000, self.webcam_handler.start)

#     def after(self, delay_ms, func, *args):
#         def wrapper():
#             try:
#                 func(*args)
#             except Exception as e:
#                 print(f"åå°ä»»åŠ¡å‡ºé”™: {e}")
#         t = threading.Timer(delay_ms / 1000.0, wrapper)
#         t.daemon = True
#         t.start()

#     def update_status(self, text: str):
#         print(f"[STATUS] {text}")

#     def broadcast_frame(self, image: Image.Image):
#         """
#         [ä¿®å¤ç‰ˆ] å®æ—¶è§†é¢‘æµé€šé“
#         ä½¿ç”¨ run_coroutine_threadsafe è·¨çº¿ç¨‹å‘é€
#         """
#         try:
#             # 1. å¦‚æœä¸»å¾ªç¯æ²¡å‡†å¤‡å¥½ï¼Œå°±å…ˆä¸å‘
#             if not global_main_loop:
#                 return

#             # 2. å›¾ç‰‡å‹ç¼©
#             buffered = BytesIO()
#             img_resized = image.resize((640, 360)) 
#             img_resized.save(buffered, format="JPEG", quality=50)
#             img_str = base64.b64encode(buffered.getvalue()).decode()
            
#             payload = {
#                 "type": "video_frame",
#                 "data": f"data:image/jpeg;base64,{img_str}"
#             }
            
#             # 3. [æ ¸å¿ƒä¿®å¤] çº¿ç¨‹å®‰å…¨å‘é€ï¼
#             # å‘Šè¯‰ä¸»çº¿ç¨‹çš„ Loopï¼šâ€œå˜¿ï¼Œå¸®æˆ‘æ‰§è¡Œä¸€ä¸‹ manager.broadcastâ€
#             asyncio.run_coroutine_threadsafe(manager.broadcast(payload), global_main_loop)
            
#         except Exception as e:
#             pass

#     def handle_analysis_result(self, timestamp, analysis_text, 
#                                behavior_num, behavior_desc, 
#                                emotion, screenshot,
#                                complex_emotion=None, 
#                                emotion_vector=None):
#         print(f"ğŸš€ [åˆ†æå®Œæˆ] è¡Œä¸º:{behavior_desc} | æƒ…ç»ª:{emotion}")
        
#         # å¤„ç†æˆªå›¾ç”¨äºå±•ç¤º
#         img_str = ""
#         if screenshot:
#             buffered = BytesIO()
#             screenshot.save(buffered, format="JPEG", quality=70)
#             img_str = base64.b64encode(buffered.getvalue()).decode()

#         payload = {
#             "type": "perception_update",
#             "data": {
#                 "timestamp": timestamp.isoformat(),
#                 "behavior": behavior_desc,
#                 "emotion": emotion,
#                 "complex_emotion": complex_emotion,
#                 "vector": emotion_vector,
#                 "analysis": analysis_text,
#                 "image": f"data:image/jpeg;base64,{img_str}"
#             }
#         }
        
#         # åˆ†æç»“æœé¢‘ç‡ä½ï¼Œä¹Ÿå¯ä»¥ç”¨åŒæ ·çš„æ–¹å¼å®‰å…¨å‘é€
#         if global_main_loop:
#              asyncio.run_coroutine_threadsafe(manager.broadcast(payload), global_main_loop)

# # å…¨å±€å•ä¾‹
# headless_wanqing = HeadlessApp()