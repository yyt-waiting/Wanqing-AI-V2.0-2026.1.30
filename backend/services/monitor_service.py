# backend/services/monitor_service.py
import asyncio
import base64
import threading
from io import BytesIO
from PIL import Image
from datetime import datetime

# å¯¼å…¥åŸæ¥çš„åº•å±‚æ ¸å¿ƒ
from ai_assistant.core.webcam_handler import WebcamHandler
from ai_assistant.core.emotion_engine import EmotionEngine
# å¯¼å…¥é€šä¿¡ç®¡å®¶å®ä¾‹


from socket_manager import manager
from services.memory_service import memory_service
from services.decision_service import decision_service

class MonitorService:
    """
    ã€è§†è§‰ä¸æ„ŸçŸ¥æœåŠ¡ã€‘
    åŸèº«ä»½: bridge.py / HeadlessApp
    èŒè´£: è¿æ¥åº•å±‚ç¡¬ä»¶æ‘„åƒå¤´ä¸ Web é€šä¿¡å±‚ï¼Œè´Ÿè´£è§†é¢‘æ¨æµä¸æ„ŸçŸ¥ç»“æœåˆ†å‘ã€‚
    """
    def __init__(self):
        self.status_text = "åˆå§‹åŒ–ä¸­..."
        # åˆå§‹åŒ–æƒ…æ„Ÿå¼•æ“ (å­¦æœ¯æ•°å­¦æ¨¡å‹)
        self.emotion_engine = EmotionEngine()
        # åˆå§‹åŒ–æ‘„åƒå¤´å¤„ç†å™¨ï¼Œå¹¶æŠŠè‡ªå·±ä½œä¸º app ä¼ å…¥ (Adapter Pattern)
        self.webcam_handler = WebcamHandler(self)
        self.main_loop = None # ç”¨äºè·¨çº¿ç¨‹é€šä¿¡çš„å¥æŸ„

    def start(self, loop):
        """ç”±ä¸»çº¿ç¨‹å¯åŠ¨æœåŠ¡"""
        self.main_loop = loop
        print("ğŸ“¸ [MonitorService] å¯åŠ¨æ‘„åƒå¤´æ•è·çº¿ç¨‹...")
        # å»¶è¿Ÿ 1 ç§’å¯åŠ¨ï¼Œç¡®ä¿äº‹ä»¶å¾ªç¯å·²å®Œå…¨ç¨³å®š
        threading.Timer(1.0, self.webcam_handler.start).start()

    # --- å…¼å®¹æ€§æ¥å£: æ¬ºéª— WebcamHandler çš„å›è°ƒ ---
    
    def update_status(self, text: str):
        """æ¨¡æ‹ŸåŸ Tkinter çš„çŠ¶æ€æ æ›´æ–°"""
        print(f"ğŸ‘ï¸ [Perception Status] {text}")

    def after(self, delay_ms, func, *args):
        """æ¨¡æ‹ŸåŸ Tkinter çš„å®šæ—¶ä»»åŠ¡"""
        def wrapper():
            try: func(*args)
            except Exception as e: print(f"âŒ åå°ä»»åŠ¡å‡ºé”™: {e}")
        t = threading.Timer(delay_ms / 1000.0, wrapper)
        t.daemon = True
        t.start()

    # --- æ ¸å¿ƒæ•°æ®åˆ†å‘æ¥å£ ---

    def broadcast_frame(self, image: Image.Image):
        """
        [å¿«è½¦é“] å®æ—¶è§†é¢‘æµ
        ç”± WebcamHandler åœ¨å…¶ç‹¬ç«‹çº¿ç¨‹ä¸­é«˜é¢‘è°ƒç”¨ (çº¦ 20fps)
        """
        if not self.main_loop: return
        
        try:
            # 1. å‹ç¼©å›¾åƒä»¥æå‡ B/S ä¼ è¾“é€Ÿåº¦
            buffered = BytesIO()
            img_resized = image.resize((640, 360)) 
            img_resized.save(buffered, format="JPEG", quality=50) # 50%è´¨é‡è¶³å¤Ÿé¢„è§ˆ
            
            # 2. è½¬ä¸º Base64 å­—ç¬¦ä¸²
            img_str = base64.b64encode(buffered.getvalue()).decode()
            
            payload = {
                "type": "video_frame",
                "data": f"data:image/jpeg;base64,{img_str}"
            }
            
            # 3. çº¿ç¨‹å®‰å…¨åœ°æ‰”è¿› Socket ç®¡ç†å™¨çš„é˜Ÿåˆ—ä¸­
            self.main_loop.call_soon_threadsafe(manager.broadcast, payload)
        except Exception:
            pass # è§†é¢‘æµå…è®¸å°‘é‡æ‰å¸§ï¼Œä¸æŠ¥é”™

    def handle_analysis_result(self, timestamp, analysis_text, 
                               behavior_num, behavior_desc, 
                               emotion, screenshot,
                               complex_emotion=None, 
                               emotion_vector=None):
        """
        [æ…¢è½¦é“] AI åˆ†æç»“æœ
        å½“ Qwen-VL å®Œæˆåˆ†æåè°ƒç”¨
        """
        print(f"ğŸš€ [è§†è§‰åˆ†æå®Œæˆ] è¡Œä¸º:{behavior_desc} | æƒ…ç»ª:{emotion}")

         # === [æ–°å¢] æ¯ä¸€è½®åˆ†æç»“æœå‡ºæ¥åï¼Œç«‹å³å­˜å…¥æœ¬åœ°æ—¥å¿— ===
        observation_data = {
            "timestamp": timestamp,
            "behavior_num": behavior_num,
            "behavior_desc": behavior_desc,
            "emotion": emotion,
            "complex_emotion": complex_emotion,
            "vector": emotion_vector,
            "analysis": analysis_text
        }
        memory_service.save_log(observation_data)
        # ===============================================
        #åæœŸä¼šæ”¹å˜åº”è¯¥ï¼Ÿ
        arousal = self.emotion_engine.get_arousal_level()
        
        # å¼‚æ­¥å¯åŠ¨å†³ç­–ä»»åŠ¡ (ä¸é˜»å¡ä¸»å¾ªç¯)
        if self.main_loop:
            asyncio.run_coroutine_threadsafe(
                decision_service.process_new_observation(
                    behavior_desc, emotion, complex_emotion, arousal
                ), 
                self.main_loop
            )



        # å¤„ç†æˆªå›¾
        img_str = ""
        if screenshot:
            buffered = BytesIO()
            screenshot.save(buffered, format="JPEG", quality=70)
            img_str = base64.b64encode(buffered.getvalue()).decode()

        # æ‰“åŒ…æ„ŸçŸ¥æ•°æ®
        payload = {
            "type": "perception_update",
            "data": {
                "timestamp": timestamp.isoformat(),
                "behavior": behavior_desc,
                "emotion": emotion,
                "complex_emotion": complex_emotion,
                "vector": emotion_vector,
                "analysis": analysis_text,
                "image": f"data:image/jpeg;base64,{img_str}"
            }
        }
        
        # åŒæ ·æ”¾å…¥é˜Ÿåˆ—å‘é€
        if self.main_loop:
            self.main_loop.call_soon_threadsafe(manager.broadcast, payload)

# å•ä¾‹å¯¼å‡º
monitor_service = MonitorService()